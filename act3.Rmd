---
title: "Resolución Actividad 1 máster Bioinformática UNIR (2023)"
author: "Andres Atencia Ortega; Sergio Bedoya; Marcela Casafus"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

Cargamos las librerías a utilizar

```{r}
library(tidyverse)
library(FactoMineR)
library(ggplot2)
library(nortest)
```

## Data cleaning

```{r}
# Cargamos los datos
df <- read.csv("mubio02_act3_alimentos_nutrientes_4900.csv")
head(df)
```

```{r}
# Verificamos por datos nulos
any(is.na(df)) # Acá vemos que sí hay datos nulos

# Vemos que porcentaje representan esos nulos
#colSums(is.na(df)) / nrow(df) * 100

# Dado que solo hay nulos en 6 columnas limitamos el print a esas columnas
colSums(is.na(
  df[, c("estado_civil", "colesterol", "hdl", "HTA", "hipercolesterolemia", "hipertrigliceridemia")])
  ) / nrow(df) * 100

```

Observamos que solo hay datos nulos en 6 columnas, que los nulos representan un porcentaje muy bajo y las columnas corresponden a datos que han sido discretizados, por lo que podemos imputar estos datos por la moda.

```{r}
# Creamos una función para calcular la moda
mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# Columnas a procesar
columnas <- c("estado_civil", "colesterol", "hdl", "HTA", "hipercolesterolemia", "hipertrigliceridemia")

# Iterar sobre las columnas
for (columna in columnas) {
  # Calcular la moda de la columna actual
  moda <- mode(df[[columna]])
  
  # Reemplazar valores nulos con la moda
  df[[columna]][is.na(df[[columna]])] <- ifelse(is.na(df[[columna]]), moda, df[[columna]])
}

# Verificamos nulos
any(is.na(df))

```

Ahora procedemos a dar formato a las columnas discretizadas:
```{r}
#variables <- c("sexo", "estado_civil", "tabaco", "colesterol", "hdl", "HTA", "hipercolesterolemia", "hipertrigliceridemia",
#               "ECV_prev", "diab_prev", "hta_prev", "depres_prev", "FA_prev", "cancer_prev")

#for (variable in variables) {
#  df[[variable]] <- as.factor(df[[variable]])
#}

#head(df)
```

## PCA

Verificamos la normalidad de los datos:

```{r}
# Normalidad de los alimentos:
# Anderson-Darling para cada columna

p_values <- c() # Inicializamos un vector par guardar los p values
variables <- unlist(colnames(df[, 28:177])) # Creamos un vector con el nombre de las columnas

# Iteramos para cada alimento y nutriente aplicando el test
for (varialble in variables) {
  # Calculamos el test de normalidad y guardamos los p values en el vector creado
  p_values <- c(p_values, ad.test(df[[varialble]])$p.value)
}

# Creamos un data frame
tabla_normalidad <- data.frame(
  "Variable"=variables,
  "Test"=c("Anderson-Darling"),
  "Valor p"=p_values
  )

# Interpretamos los resultados
## Creamos una función para interpretar
interpretador <- function(pvalue) {
  if (pvalue < 0.05) {
    return("Distribucion No normal")
  } else if (pvalue > 0.05) {
    return("Distribucion Normal")
  } else {
    return("No significativo")
  }
}

## Creamos una nueva columna con la interpretación
tabla_normalidad$Interpretacion <- interpretador(tabla_normalidad$Valor.p)

# Guardamos
write.table(tabla_normalidad, file = "tabla_normalidad.csv")

# Visualizamos
tabla_normalidad
```


```{r}
# Análisis de componentes principales
pca.results <- PCA(X = df[,28:177], scale.unit = TRUE, graph = FALSE)
```

Calculamos la proporción de varianza explicada de cada componente (R2) y graficamos en la 2da tabla.

```{r}
# Seleccionamos la varianza explicada redondeada
p_var <- data.frame(R2 = round(pca.results$eig[, 2],2))
# Agregamos una columna para los componentes
p_var$Componentes <- row.names(p_var)

# Ordenamos las columnas como se nos solicita
p_var <- p_var %>%
  select(Componentes, R2)

# Guardamos la tabla
write.table(p_var, file = "tabla_componentes_R2.csv")

# Mostramos
p_var
```

```{r}
# Obtener las cargas y tabularlas
cargas <- as.data.frame(round(pca.results$var$coord,2))

# Añadir información sobre las variables
cargas$Variable <- rownames(cargas)

# Imprimir las cargas tabuladas
tabla_cargas <- cargas %>%
  select(
    Variable, "Componente1"=Dim.1, "Componente2"=Dim.2,
    "Componente3"=Dim.3, "Componente4"=Dim.4, "Componente5"=Dim.5
    )

write.table(tabla_cargas, file = "Tabla_cargas.csv")

tabla_cargas
```

```{r}
# Usamos gtsummary para hacer la tabla
tabla_descriptiva <- df_tabla4 %>%
  tbl_strata(
    strata = sexo, #agrupamos primero por sexo
    .tbl_fun = ~ .x %>%
      tbl_summary(by = categoriaIMC, #luego por la categoría de IMC
                  # Explicación abajo
                  type = list(starts_with("alimento") ~ "continuous"),
                  # Calculamos los estadísticos
                  statistic = all_continuous()~"{mean} ({sd})"
                    ) %>%
      # Modificamos el titulo
      modify_header(label = "**Variables**")%>%
      # Agregamos el test de Welch
        add_p(
          all_continuous()~"t.test",
          pvalues_fun=~style_pvalue(.x, digits = 3) # 3 digitos
          )
    ) %>%
  bold_labels()

# Visualizamos
tabla4
```


## Modelo regresión logística

## Conclusiones y recomendaciones
