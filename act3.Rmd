---
title: "Resolución Actividad 1 máster Bioinformática UNIR (2023)"
author: "Andres Atencia Ortega; Sergio Bedoya; Marcela Casafus"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

Cargamos las librerías a utilizar

```{r}
library(tidyverse)
library(stats)
library(ggplot2)
library(nortest)
```

## Data cleaning

```{r}
# Cargamos los datos
df <- read.csv("mubio02_act3_alimentos_nutrientes_4900.csv")
head(df)
```

```{r}
# Verificamos por datos nulos
any(is.na(df)) # Acá vemos que sí hay datos nulos

# Vemos que porcentaje representan esos nulos
#colSums(is.na(df)) / nrow(df) * 100

# Dado que solo hay nulos en 6 columnas limitamos el print a esas columnas
colSums(is.na(
  df[, c("estado_civil", "colesterol", "hdl", "HTA", "hipercolesterolemia", "hipertrigliceridemia")])
  ) / nrow(df) * 100

```

Observamos que solo hay datos nulos en 6 columnas, que los nulos representan un porcentaje muy bajo y las columnas corresponden a datos que han sido discretizados, por lo que podemos imputar estos datos por la moda.

```{r}
# Creamos una función para calcular la moda
mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# Columnas a procesar
columnas <- c("estado_civil", "colesterol", "hdl", "HTA", "hipercolesterolemia", "hipertrigliceridemia")

# Iterar sobre las columnas
for (columna in columnas) {
  # Calcular la moda de la columna actual
  moda <- mode(df[[columna]])
  
  # Reemplazar valores nulos con la moda
  df[[columna]][is.na(df[[columna]])] <- ifelse(is.na(df[[columna]]), moda, df[[columna]])
}

# Verificamos nulos
any(is.na(df))

```

Ahora procedemos a dar formato a las columnas discretizadas:
```{r}
#variables <- c("sexo", "estado_civil", "tabaco", "colesterol", "hdl", "HTA", "hipercolesterolemia", "hipertrigliceridemia",
#               "ECV_prev", "diab_prev", "hta_prev", "depres_prev", "FA_prev", "cancer_prev")

#for (variable in variables) {
#  df[[variable]] <- as.factor(df[[variable]])
#}

#head(df)
```

## PCA

```{r}
head(df[,])
```


Verificamos la normalidad de los datos:

```{r}
# Normalidad de los alimentos:
# Anderson-Darling para cada columna

p_values <- c() # Inicializamos un vector par guardar los p values
variables <- unlist(colnames(df[, 28:177])) # Creamos un vector con el nombre de las columnas

# Iteramos para cada alimento y nutriente aplicando el test
for (varialble in variables) {
  # Calculamos el test de normalidad y guardamos los p values en el vector creado
  p_values <- c(p_values, ad.test(df[[varialble]])$p.value)
}

# Creamos un data frame
tabla_normalidad <- data.frame(
  "Variable"=variables,
  "Test"=c("Anderson-Darling"),
  "Valor p"=p_values
  )

# Interpretamos los resultados
## Creamos una función para interpretar
interpretador <- function(pvalue) {
  if (pvalue < 0.05) {
    return("Distribucion No normal")
  } else if (pvalue > 0.05) {
    return("Distribucion Normal")
  } else {
    return("No significativo")
  }
}

## Creamos una nueva columna con la interpretación
tabla_normalidad$Interpretacion <- interpretador(tabla_normalidad$Valor.p)

# Guardamos
write.table(tabla_normalidad, file = "tabla_normalidad.csv")

# Visualizamos
tabla_normalidad
```


```{r}
# Análisis de componentes principales
## Ignoramos la primera columan de id
## Scale True indica normalizar los datos
pca.results <- prcomp(df[,2:177], scale = TRUE)
names(pca.results)
```

```{r}
dim(pca.results$rotation)
```


## Modelo regresión logística

## Conclusiones y recomendaciones
